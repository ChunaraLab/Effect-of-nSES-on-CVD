{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a183c6",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d84ed",
   "metadata": {},
   "source": [
    "## food resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c44dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ = \"data/raw_data_file/neighborhood/jhs_nets.csv\"\n",
    "nfood_data = pd.read_csv(filename_)\n",
    "\n",
    "nfood_data = nfood_data[['SUBJID', 'exam', 'N_UNFAV_CT00']]\n",
    "\n",
    "nfood_data = nfood_data.rename(columns={\"SUBJID\": \"subjid\", \"exam\":\"visit\"})\n",
    "\n",
    "visit_mapping = {'exam1': 1,'exam2': 2, 'exam3':3}\n",
    "nfood_data = nfood_data.assign(visit  = nfood_data.visit.map(visit_mapping))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2508a",
   "metadata": {},
   "source": [
    "## racial segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e46a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ = \"data/raw_data_file/neighborhood/jhs_rs.csv\"\n",
    "rs_data = pd.read_csv(filename_)\n",
    "\n",
    "rs_data = rs_data[['SUBJID', 'exam', 'G_bla_rk']]\n",
    "\n",
    "rs_data = rs_data.rename(columns={\"SUBJID\": \"subjid\", \"exam\":\"visit\"})\n",
    "\n",
    "visit_mapping = {'exam1': 1,'exam2': 2}\n",
    "rs_data = rs_data.assign(visit  = rs_data.visit.map(visit_mapping))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41c47a",
   "metadata": {},
   "source": [
    "## visit dates and other covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ = \"data/raw_data_file/analysis.csv\"\n",
    "analysis_data = pd.read_csv(filename_)\n",
    "analysis_data = analysis_data[['subjid', 'visit', 'VisitDate',\n",
    "                      'nutrition3cat','PA3cat',\n",
    "                      'fmlyinc','alc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3548a9b",
   "metadata": {},
   "source": [
    "## Common dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b43e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_data = pd.read_csv(\"data/processed/common_data_jhs.csv\")\n",
    "\n",
    "common_data = common_data[['subjid','visit',\n",
    "                           'nSES','nbSESpc2score','nbK3paFacilities',\n",
    "                           'currentSmoker','Diabetes','sex','age','sbp','hdl','totchol',\n",
    "                          'MIHx','strokeHx','CHDHx','CVDHx']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbf5b8",
   "metadata": {},
   "source": [
    "## merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = common_data.merge(nfood_data, how='left', on=['subjid','visit'])\n",
    "merge2 = merge1.merge(rs_data, how='left', on=['subjid','visit'])\n",
    "merge3 = merge2.merge(analysis_data, how='left', on=['subjid','visit'])\n",
    "merge = merge3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## map gender and income\n",
    "\n",
    "gender_mapping = {'Female':0,'Male':1}\n",
    "income_mapping = {'A':1,'B':1,'C':1,\n",
    "                 'D':2,'E':2,'F':2,\n",
    "                 'G':3,'H':3,'I':3,\n",
    "                 'J':4,'K':4}\n",
    "merge = merge.assign(gender = merge['sex'].map(gender_mapping))\n",
    "merge = merge.assign(fmlyinc = merge['fmlyinc'].map(income_mapping))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de70a4",
   "metadata": {},
   "source": [
    "## check variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckVar(variable, df=merge, iscategorical = False): \n",
    "    print(variable)\n",
    "    df_v1 = df[df[\"visit\"] == 1]\n",
    "    df_v2 = df[df[\"visit\"] == 2]\n",
    "    df_v3 = df[df[\"visit\"] == 3]\n",
    "    nan_v1 = df_v1[variable].isnull().sum()\n",
    "    nan_v2 = df_v2[variable].isnull().sum()\n",
    "    nan_v3 = df_v3[variable].isnull().sum()\n",
    "    \n",
    "    # categorical variables\n",
    "    if iscategorical == True:\n",
    "        if nan_v1 < 1000:\n",
    "            print(\"#na in V1 =\",nan_v1,\"\\n\",\n",
    "                  df_v1[variable].value_counts() / len(df_v1))\n",
    "        else:\n",
    "            print(\"#na in V1 =\",nan_v1,\"not available\")\n",
    "        \n",
    "        if nan_v2 < 1000:\n",
    "            print(\"#na in V2 =\",nan_v2,\"\\n\",\n",
    "                  df_v2[variable].value_counts() / len(df_v2))\n",
    "        else:\n",
    "            print(\"#na in V2 =\",nan_v2,\"not available\")\n",
    "            \n",
    "        if nan_v3 < 1000:\n",
    "            print(\"#na in V3 =\",nan_v3,\"\\n\",\n",
    "                  df_v3[variable].value_counts() / len(df_v3),'\\n')\n",
    "        else:\n",
    "            print(\"#na in V3 =\",nan_v3,\"not available\\n\")\n",
    "    \n",
    "    # continuous variables\n",
    "    if iscategorical == False:\n",
    "        if nan_v1 < 1000:\n",
    "            print(\"#na in V1 =\",nan_v1)\n",
    "            print(df_v1[variable].describe())\n",
    "                  \n",
    "        else:\n",
    "            print(\"#na in V1 =\",nan_v1,\"not available\")\n",
    "            \n",
    "        if nan_v2 < 1000:\n",
    "            print(\"#na in V2 =\",nan_v2,\"\\n\",\n",
    "                  \"mean =\", np.nanmean(df_v2[variable]),\"\\n\",\n",
    "                 \"Variance =\", np.nanvar(df_v2[variable]))\n",
    "        else:\n",
    "            print(\"#na in V2 =\",nan_v2,\"not available\")\n",
    "            \n",
    "        if nan_v3 < 1000:\n",
    "            print(\"#na in V3 =\",nan_v3,\"\\n\",\n",
    "                  \"mean =\", np.nanmean(df_v3[variable]),\"\\n\",\n",
    "                 \"Variance =\", np.nanvar(df_v3[variable]),'\\n')\n",
    "        else:\n",
    "            print(\"#na in V3 =\",nan_v3,\"not available\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(CheckVar, ['nbSESpc2score','nbK3paFacilities','N_UNFAV_CT00',\n",
    "                           'sportIndex', 'hyIndex','activeIndex','darkgrnVeg', 'eggs','fish']))\n",
    "\n",
    "print(CheckVar('hdl', df=merge, iscategorical = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot distribution and check the edge for quantile cutting\n",
    "\n",
    "dat1 = merge[merge['visit'] == 1]\n",
    "dat2 = merge[merge['visit'] == 2]\n",
    "dat3 = merge[merge['visit'] == 3]\n",
    "\n",
    "\n",
    "def plot_distribution(df,variable):\n",
    "    for var in variable:\n",
    "        plt.hist(df[var], bins=20, edgecolor='black', alpha=0.5)\n",
    "\n",
    "        quantiles = df[var].quantile([0.25, 0.5, 0.75, 1])\n",
    "        plt.axvline(quantiles[0.25], color='r', linestyle='--', label='Q1')\n",
    "        plt.axvline(quantiles[0.5], color='g', linestyle='--', label='Median')\n",
    "        plt.axvline(quantiles[0.75], color='b', linestyle='--', label='Q3')\n",
    "        plt.axvline(quantiles[1], color='m', linestyle='--', label='Max')\n",
    "\n",
    "        plt.xlabel(var)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "exposures = ['nbSESpc2score','nbK3paFacilities','N_UNFAV_CT00','G_bla_rk',\n",
    "                           'sportIndex', 'hyIndex','activeIndex','darkgrnVeg', 'eggs','fish']\n",
    "\n",
    "plot_distribution(dat1, exposures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a525f4c",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabefeb3",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1176e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcome(df):\n",
    "    df['y'] = 0\n",
    "    df.loc[\n",
    "       (df['MIHx']==1.0) |\n",
    "       (df['strokeHx']==1.0) |\n",
    "       (df['CHDHx']==1.0)|\n",
    "       (df['CVDHx']==1.0),\n",
    "       'y'] = 1\n",
    "    return df\n",
    "\n",
    "def fillna_cat(df,cat_feat):\n",
    "    for feat in cat_feat:\n",
    "        df[feat].fillna(df[feat].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def fillna_cont(df,cont_feat):\n",
    "    df= df.fillna((df[cont_feat].mean()))\n",
    "    return df\n",
    "\n",
    "\n",
    "def quantile_exp(df,con_exp_feat):\n",
    "    for feat in con_exp_feat:\n",
    "        df[feat] = df[feat].transform(lambda x: pd.qcut(x.rank(method='first'), \n",
    "                                                         q = [0, 0.25, 0.5, 0.75, 1], labels = [1,2,3,4]))\n",
    "        df[feat] = pd.to_numeric(df[feat])\n",
    "    return df\n",
    "\n",
    "def standardize(df,con_index):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df[con_index],) \n",
    "    df[con_index] = scaler.transform(df[con_index], copy = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "## complete pipeline\n",
    "\n",
    "def process(df,cont_feat,cat_feat,con_exp_feat):\n",
    "    df = get_outcome(df)\n",
    "    \n",
    "    df = fillna_cat(df,cat_feat)\n",
    "    \n",
    "    df = fillna_cont(df,cont_feat)\n",
    "    df = standardize(df,cont_feat)\n",
    "        \n",
    "    df = fillna_cont(df,con_exp_feat)\n",
    "    df = quantile_exp(df,con_exp_feat)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3887b7ff",
   "metadata": {},
   "source": [
    "## process by exam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82caa078",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = merge[merge['visit'] == 1]\n",
    "dat2 = merge[merge['visit'] == 2]\n",
    "dat3 = merge[merge['visit'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b051859",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visit 1\n",
    "\n",
    "con_exp_feat1 = ['nbSESpc2score','nbK3paFacilities','N_UNFAV_CT00','G_bla_rk']\n",
    "\n",
    "cont_feat1 = ['sbp', 'hdl', 'totchol']\n",
    "\n",
    "cat_feat1 = ['currentSmoker','Diabetes', 'gender', 'fmlyinc','nutrition3cat','PA3cat','alc']\n",
    "\n",
    "data1_processed = process(dat1,cont_feat1,cat_feat1,con_exp_feat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visit 2\n",
    "\n",
    "con_exp_feat2 = ['N_UNFAV_CT00','G_bla_rk']\n",
    "\n",
    "cont_feat2 = ['sbp']\n",
    "\n",
    "cat_feat2 = ['Diabetes', 'gender']\n",
    "\n",
    "data2_processed = process(dat2,cont_feat2,cat_feat2,con_exp_feat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d999558",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visit 3\n",
    "\n",
    "con_exp_feat3 = []\n",
    "\n",
    "cont_feat3 = ['sbp', 'hdl']\n",
    "\n",
    "cat_feat3 = ['PA3cat','Diabetes', 'gender','alc','fmlyinc']\n",
    "\n",
    "data3_processed = process(dat3,cont_feat3,cat_feat3,con_exp_feat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12728f34",
   "metadata": {},
   "source": [
    "## merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b994e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([data1_processed, data2_processed, data3_processed])\n",
    "merged.to_csv('data/jhs_preprocess_0914.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
