{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bed1a2",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03653dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a8832",
   "metadata": {},
   "source": [
    "## NETS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ = \"data/neighborhood/jhs_nets.csv\"\n",
    "nfood_data = pd.read_csv(filename_)\n",
    "\n",
    "nfood_data = nfood_data[['SUBJID', 'exam', 'N_UNFAV_CT00']]\n",
    "\n",
    "nfood_data = nfood_data.rename(columns={\"SUBJID\": \"subjid\", \"exam\":\"visit\"})\n",
    "\n",
    "visit_mapping = {'exam1': 1,'exam2': 2, 'exam3':3}\n",
    "nfood_data = nfood_data.assign(visit  = nfood_data.visit.map(visit_mapping))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf857e1",
   "metadata": {},
   "source": [
    "## racial segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ = \"data/neighborhood/jhs_rs.csv\"\n",
    "rs_data = pd.read_csv(filename_)\n",
    "\n",
    "rs_data = rs_data[['SUBJID', 'exam', 'G_bla_rk']]\n",
    "\n",
    "rs_data = rs_data.rename(columns={\"SUBJID\": \"subjid\", \"exam\":\"visit\"})\n",
    "\n",
    "visit_mapping = {'exam1': 1,'exam2': 2}\n",
    "rs_data = rs_data.assign(visit  = rs_data.visit.map(visit_mapping))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eef4d7",
   "metadata": {},
   "source": [
    "## Common dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_data = pd.read_csv(\"data/common_data_jhs.csv\")\n",
    "\n",
    "common_data = common_data[['subjid','visit',\n",
    "                           'nSES','nbSESpc2score','nbK3paFacilities',\n",
    "                           'sportIndex', 'hyIndex','activeIndex','darkgrnVeg', 'eggs','fish',\n",
    "                           'currentSmoker','Diabetes','sex','age','sbp','hdl','totchol',\n",
    "                          'MIHx','strokeHx','CHDHx','CVDHx']]\n",
    "\n",
    "common_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bfb07",
   "metadata": {},
   "source": [
    "## merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = common_data.merge(nfood_data, how='left', on=['subjid','visit'])\n",
    "merge = merge1.merge(rs_data, how='left', on=['subjid','visit'])\n",
    "merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ee9a7",
   "metadata": {},
   "source": [
    "### check variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckVar(variable, df=merge, iscategorical = False): \n",
    "    print(variable)\n",
    "    df_v1 = df[df[\"visit\"] == 1]\n",
    "    df_v2 = df[df[\"visit\"] == 2]\n",
    "    df_v3 = df[df[\"visit\"] == 3]\n",
    "    nan_v1 = df_v1[variable].isnull().sum()\n",
    "    nan_v2 = df_v2[variable].isnull().sum()\n",
    "    nan_v3 = df_v3[variable].isnull().sum()\n",
    "    \n",
    "    # categorical variables\n",
    "    if iscategorical == True:\n",
    "        if nan_v1 < 1000:\n",
    "            print(\"#na in V1 =\",nan_v1,\"\\n\",\n",
    "                  df_v1[variable].value_counts() / len(df_v1))\n",
    "        else:\n",
    "            print(\"#na in V1 =\",nan_v1,\"not available\")\n",
    "        \n",
    "        if nan_v2 < 1000:\n",
    "            print(\"#na in V2 =\",nan_v2,\"\\n\",\n",
    "                  df_v2[variable].value_counts() / len(df_v2))\n",
    "        else:\n",
    "            print(\"#na in V2 =\",nan_v2,\"not available\")\n",
    "            \n",
    "        if nan_v3 < 1000:\n",
    "            print(\"#na in V3 =\",nan_v3,\"\\n\",\n",
    "                  df_v3[variable].value_counts() / len(df_v3),'\\n')\n",
    "        else:\n",
    "            print(\"#na in V3 =\",nan_v3,\"not available\\n\")\n",
    "    \n",
    "    # continuous variables\n",
    "    if iscategorical == False:\n",
    "        if nan_v1 < 1000:\n",
    "            print(\"#na in V1 =\",nan_v1)\n",
    "            print(df_v1[variable].describe())\n",
    "                  \n",
    "        else:\n",
    "            print(\"#na in V1 =\",nan_v1,\"not available\")\n",
    "            \n",
    "        if nan_v2 < 1000:\n",
    "            print(\"#na in V2 =\",nan_v2,\"\\n\",\n",
    "                  \"mean =\", np.nanmean(df_v2[variable]),\"\\n\",\n",
    "                 \"Variance =\", np.nanvar(df_v2[variable]))\n",
    "        else:\n",
    "            print(\"#na in V2 =\",nan_v2,\"not available\")\n",
    "            \n",
    "        if nan_v3 < 1000:\n",
    "            print(\"#na in V3 =\",nan_v3,\"\\n\",\n",
    "                  \"mean =\", np.nanmean(df_v3[variable]),\"\\n\",\n",
    "                 \"Variance =\", np.nanvar(df_v3[variable]),'\\n')\n",
    "        else:\n",
    "            print(\"#na in V3 =\",nan_v3,\"not available\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(CheckVar, ['nbSESpc2score','nbK3paFacilities','N_UNFAV_CT00',\n",
    "                           'sportIndex', 'hyIndex','activeIndex','darkgrnVeg', 'eggs','fish']))\n",
    "\n",
    "print(CheckVar('hdl', df=merge, iscategorical = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e879ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot distribution and check the edge for quantile cutting\n",
    "\n",
    "dat1 = merge[merge['visit'] == 1]\n",
    "dat2 = merge[merge['visit'] == 2]\n",
    "dat3 = merge[merge['visit'] == 3]\n",
    "\n",
    "\n",
    "def plot_distribution(df,variable):\n",
    "    for var in variable:\n",
    "        plt.hist(df[var], bins=20, edgecolor='black', alpha=0.5)\n",
    "\n",
    "        quantiles = df[var].quantile([0.25, 0.5, 0.75, 1])\n",
    "        plt.axvline(quantiles[0.25], color='r', linestyle='--', label='Q1')\n",
    "        plt.axvline(quantiles[0.5], color='g', linestyle='--', label='Median')\n",
    "        plt.axvline(quantiles[0.75], color='b', linestyle='--', label='Q3')\n",
    "        plt.axvline(quantiles[1], color='m', linestyle='--', label='Max')\n",
    "\n",
    "        plt.xlabel(var)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "exposures = ['nbSESpc2score','nbK3paFacilities','N_UNFAV_CT00','G_bla_rk',\n",
    "                           'sportIndex', 'hyIndex','activeIndex','darkgrnVeg', 'eggs','fish']\n",
    "\n",
    "plot_distribution(dat1, exposures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd208ef",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4757c0",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3efcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcome(df):\n",
    "    df['y'] = 0\n",
    "    df.loc[\n",
    "       (df['MIHx']==1.0) |\n",
    "       (df['strokeHx']==1.0) |\n",
    "       (df['CHDHx']==1.0)|\n",
    "       (df['CVDHx']==1.0),\n",
    "       'y'] = 1\n",
    "    return df\n",
    "\n",
    "def fillna_cat(df,cat_feat):\n",
    "    for feat in cat_feat:\n",
    "        df[feat].fillna(df[feat].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def fillna_cont(df,cont_feat):\n",
    "    df= df.fillna((df[cont_feat].mean()))\n",
    "    return df\n",
    "\n",
    "def process_binary(df,bin_feat):\n",
    "    gender_mapping = {'Female':0,'Male':1}\n",
    "    df = df.assign(gender = df['sex'].map(gender_mapping))\n",
    "    return df\n",
    "\n",
    "def quantile_exp(df,exp_feat):\n",
    "    for feat in exp_feat:\n",
    "        df[feat] = df[feat].transform(lambda x: pd.qcut(x.rank(method='first'), \n",
    "                                                         q = [0, 0.25, 0.5, 0.75, 1], labels = [1,2,3,4]))\n",
    "        df[feat] = pd.to_numeric(df[feat])\n",
    "    return df\n",
    "\n",
    "def standardize(df,con_index):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df[con_index],) \n",
    "    df[con_index] = scaler.transform(df[con_index], copy = True)\n",
    "    return df\n",
    "\n",
    "def process(df,bin_feat,cont_feat,cat_feat,exp_feat):\n",
    "    df = get_outcome(df)\n",
    "    \n",
    "    df = process_binary(df,bin_feat)\n",
    "    \n",
    "    df = fillna_cat(df,cat_feat)\n",
    "    \n",
    "    df = fillna_cont(df,cont_feat)\n",
    "    df = standardize(df,cont_feat)\n",
    "        \n",
    "    df = fillna_cont(df,exp_feat)\n",
    "    df = quantile_exp(df,exp_feat)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c51511",
   "metadata": {},
   "source": [
    "## process by exam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e64773",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = merge[merge['visit'] == 1]\n",
    "dat2 = merge[merge['visit'] == 2]\n",
    "dat3 = merge[merge['visit'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58866449",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_feat1 = ['sex']\n",
    "\n",
    "exp_feat1 = ['nbSESpc2score','nbK3paFacilities','N_UNFAV_CT00','G_bla_rk',\n",
    "            'sportIndex', 'hyIndex','activeIndex','darkgrnVeg', 'eggs','fish']\n",
    "\n",
    "cont_feat1 = ['sbp', 'hdl', 'totchol']\n",
    "\n",
    "cat_feat1 = ['currentSmoker','Diabetes', 'gender']\n",
    "\n",
    "data1_processed = process(dat1,bin_feat1,cont_feat1,cat_feat1,exp_feat1)\n",
    "data1_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c470e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_feat2 = ['sex']\n",
    "\n",
    "exp_feat2 = ['N_UNFAV_CT00','G_bla_rk']\n",
    "\n",
    "cont_feat2 = ['sbp']\n",
    "\n",
    "cat_feat2 = ['Diabetes', 'gender']\n",
    "\n",
    "data2_processed = process(dat2,bin_feat2,cont_feat2,cat_feat2,exp_feat2)\n",
    "data2_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac42958",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_feat3 = ['sex']\n",
    "\n",
    "exp_feat3 = ['sportIndex', 'hyIndex','activeIndex']\n",
    "\n",
    "cont_feat3 = ['sbp', 'hdl']\n",
    "\n",
    "cat_feat3 = ['Diabetes', 'gender']\n",
    "\n",
    "data3_processed = process(dat3,bin_feat3,cont_feat3,cat_feat3,exp_feat3)\n",
    "data3_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ae17b",
   "metadata": {},
   "source": [
    "## merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c54724",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([data1_processed, data2_processed, data3_processed])\n",
    "merged.to_csv('data/jhs_complete_0718.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbcdcd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c823b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b64512ed",
   "metadata": {},
   "source": [
    "# check raw data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=pd.read_csv(\"data/jhs_data.csv\")\n",
    "\n",
    "dat[dat['visit']==3].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=pd.read_csv(\"data/common_data_jhs.csv\")\n",
    "dat[dat['visit']==3].head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
