{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lifelines import CoxPHFitter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', 100)\n",
    "\n",
    "\n",
    "# calibration slope\n",
    "def logit(p):\n",
    "  return np.log(p/(1-p))\n",
    "\n",
    "def calibration_slope(ground_truth, probabilities):\n",
    "  probabilities = np.array(probabilities)\n",
    "  logit_probabilities = logit(probabilities).reshape(-1,1)\n",
    "  lr = LogisticRegression(penalty='none', fit_intercept=True).fit(logit_probabilities, ground_truth)\n",
    "  return lr.coef_.item()\n",
    "\n",
    "# roc curve\n",
    "def PlotROC(y_test,  y_pred_proba, AUCvalue):\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "    plt.text(0.3,0, \"\".join(['AUC =', AUCvalue]), fontsize = 15)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "# frequency plot\n",
    "def PlotFreq(y_pred_proba):\n",
    "    y_pred_plot = pd.Series(y_pred_proba)\n",
    "    y_pred_plot.plot.hist(grid=True, bins=20, rwidth=0.9,\n",
    "                       color='#607c8e')\n",
    "    plt.xlabel('Prob')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36379236",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoxMetrics:\n",
    "    ## input\n",
    "    def __init__(self, data, pred_sf, visit):   ## con_var & cate_var are lists of variable names\n",
    "        self.data = data\n",
    "        self.pred_sf = pred_sf\n",
    "        self.y_true = \"Y\" + str(visit)\n",
    "        self.y_prob = 'sf_V' + str(visit)\n",
    "        self.y_pred = 'pred_V' + str(visit)\n",
    "        \n",
    "        \n",
    "    ### complete the test df with predicted risk and labeled prediction\n",
    "        self.data['sf_V1'] = 1 - self.pred_sf.loc[:, 1]\n",
    "        self.data['sf_V2'] = 1-self.pred_sf.loc[:, 2]\n",
    "        self.data['sf_V3'] = 1-self.pred_sf.loc[:, 3]\n",
    "        \n",
    "        # calculate optimized threshold\n",
    "        fpr, tpr, thresholds = roc_curve(self.data[self.y_true], self.data[self.y_prob]) \n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        self.threshold = thresholds[optimal_idx]\n",
    "        print(\"optimized threshold =\",self.threshold)\n",
    "        \n",
    "        # label the prediction with optimized threshold\n",
    "        self.data['pred_V1'] = 0\n",
    "        self.data.loc[self.data['sf_V1'] >= self.threshold, 'pred_V1'] = 1\n",
    "        self.data['pred_V2'] = 0\n",
    "        self.data.loc[self.data['sf_V2'] >= self.threshold, 'pred_V2'] = 1\n",
    "        self.data['pred_V3'] = 0\n",
    "        self.data.loc[self.data['sf_V3'] >= self.threshold, 'pred_V3'] = 1\n",
    "        \n",
    "        print(\"Prediction completed\")    \n",
    "    \n",
    "  \n",
    "    ### subgrouping\n",
    "        self.te_low = self.data[self.data[\"nSES\"] == 0] \n",
    "        self.te_high = self.data[self.data[\"nSES\"] == 1]\n",
    "        self.te_f = self.data[self.data[\"gender\"] == 0]\n",
    "        self.te_m = self.data[self.data[\"gender\"] == 1]\n",
    "        \n",
    "        # subgroups by both gender and nses\n",
    "        self.f_low = self.data[(self.data['gender'] == 0) & (self.data[\"nSES\"] == 0)]\n",
    "        self.f_high = self.data[(self.data[\"gender\"] == 0) & self.data[\"nSES\"] == 1]\n",
    "        self.m_low = self.data[(self.data['gender'] == 1) & (self.data[\"nSES\"] == 0)]\n",
    "        self.m_high = self.data[(self.data['gender'] == 1) & (self.data[\"nSES\"] == 1)]\n",
    "        \n",
    "        print(\"Subgrouping\")\n",
    "   \n",
    "    \n",
    "    # model performance metrics\n",
    "        print(\"\\n>>>Model performance\")\n",
    "        self.metrics()\n",
    "    \n",
    "    \n",
    "    def metrics(self):\n",
    "        \n",
    "        # AUC\n",
    "        print(\"\\n>>>>AUC\")\n",
    "        auc = metrics.roc_auc_score(self.data[self.y_true], self.data[self.y_prob])\n",
    "        print(\"AUC=\", auc)\n",
    "        \n",
    "        auc_low = metrics.roc_auc_score(self.te_low[self.y_true], self.te_low[self.y_prob])\n",
    "        auc_high = metrics.roc_auc_score(self.te_high[self.y_true], self.te_high[self.y_prob])\n",
    "        auc_f = metrics.roc_auc_score(self.te_f[self.y_true], self.te_f[self.y_prob])\n",
    "        auc_m = metrics.roc_auc_score(self.te_m[self.y_true], self.te_m[self.y_prob])\n",
    "        print(\"AUC in low nSES group = \",auc_low,\n",
    "             \"\\n AUC in high nSES group = \",auc_high,\n",
    "              \"\\n disparity in AUC = \",abs(auc_low - auc_high),\n",
    "             \"\\n AUC in female group = \",auc_f,\n",
    "             \"\\n AUC in male group = \",auc_m)\n",
    "        \n",
    "        auc_f_low = metrics.roc_auc_score(self.f_low[self.y_true], self.f_low[self.y_prob])\n",
    "        auc_f_high = metrics.roc_auc_score(self.f_high[self.y_true], self.f_high[self.y_prob])\n",
    "        auc_m_low = metrics.roc_auc_score(self.m_low[self.y_true], self.m_low[self.y_prob])\n",
    "        auc_m_high = metrics.roc_auc_score(self.m_high[self.y_true], self.m_high[self.y_prob])\n",
    "        print(\"AUC in f_low group = \",auc_f_low,\n",
    "             \"\\n AUC in f_high group = \",auc_f_high,\n",
    "             \"\\n AUC in m_low group = \",auc_m_low,\n",
    "             \"\\n AUC in m_high group = \",auc_m_high)\n",
    "        \n",
    "        # calibration slope\n",
    "        print(\"\\n>>>>Calibration Slope\")\n",
    "        print(\"calibration slope =\",calibration_slope(self.data[self.y_true], self.data[self.y_prob]))\n",
    "        \n",
    "        print(\"CS in low_nses group = \",calibration_slope(self.te_low[self.y_true], self.te_low[self.y_prob]),\n",
    "             \"\\n CS in high_nses group = \",calibration_slope(self.te_high[self.y_true], self.te_high[self.y_prob]),\n",
    "            \"\\n CS in f_low group = \",calibration_slope(self.f_low[self.y_true], self.f_low[self.y_prob]),\n",
    "             \"\\n CS in f_high group = \",calibration_slope(self.f_high[self.y_true], self.f_high[self.y_prob]),\n",
    "             \"\\n CS in m_low group = \",calibration_slope(self.m_low[self.y_true], self.m_low[self.y_prob]),\n",
    "             \"\\n CS in m_high group = \",calibration_slope(self.m_high[self.y_true], self.m_high[self.y_prob]))      \n",
    "        \n",
    "        # TPR&FPR\n",
    "        print(\"\\n>>>>TPR&FPR\")\n",
    "        def TprFpr(TrueLabel, PredLable, subgroup):\n",
    "            CM = confusion_matrix(TrueLabel, PredLable)\n",
    "            tpr = CM[1,1]/(CM[1,1]+CM[1,0])\n",
    "            fpr = CM[0,1]/(CM[0,1]+CM[0,0])\n",
    "            print(subgroup,\": \\n\",\n",
    "                  \"\".join(['TPR=', str(tpr), ',','FPR=', str(fpr)]))\n",
    "    \n",
    "        TprFpr(self.data[self.y_true], self.data[self.y_pred],\"whole\")\n",
    "        TprFpr(self.te_low[self.y_true], self.te_low[self.y_pred],\"low\")\n",
    "        TprFpr(self.te_high[self.y_true], self.te_high[self.y_pred],\"high\")\n",
    "        TprFpr(self.f_low[self.y_true], self.f_low[self.y_pred],\"f_low\")\n",
    "        TprFpr(self.f_high[self.y_true], self.f_high[self.y_pred],\"f_high\")\n",
    "        TprFpr(self.m_low[self.y_true], self.m_low[self.y_pred], \"m_low\")\n",
    "        TprFpr(self.m_high[self.y_true], self.m_high[self.y_pred],\"m_high\")\n",
    "        \n",
    "        # roc curve\n",
    "        PlotROC(self.data[self.y_true], self.data[self.y_prob], str(auc))\n",
    "        \n",
    "        # frequency plot\n",
    "        PlotFreq(self.data[self.y_prob])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa84646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apr 4\n",
    "cox_tr = pd.read_csv('data/jhs_tr_stratified.csv')\n",
    "cox_te = pd.read_csv('data/jhs_te_stratified.csv')\n",
    "\n",
    "cox_tr = cox_tr.loc[:, ~cox_tr.columns.isin(['subjid', 'y_tot'])]\n",
    "cox_te = cox_te.loc[:, ~cox_te.columns.isin(['subjid', 'y_tot'])]\n",
    "\n",
    "# recode event and time\n",
    "\n",
    "cox_tr['event'] = 0\n",
    "cox_tr['time'] = 3\n",
    "cox_te['event'] = 0\n",
    "cox_te['time'] = 3\n",
    "\n",
    "## incidence in V1\n",
    "cox_tr.loc[cox_tr['y1'] == 1,'event'] = 1\n",
    "cox_tr.loc[cox_tr['y1'] == 1,'time'] = 1\n",
    "cox_te.loc[cox_te['y1'] == 1,'event'] = 1\n",
    "cox_te.loc[cox_te['y1'] == 1,'time'] = 1\n",
    "\n",
    "## incidence in V2\n",
    "v2_index = (cox_tr['y2'] == 1) & (cox_tr['y1'] == 0)\n",
    "cox_tr.loc[v2_index,'event'] = 1\n",
    "cox_tr.loc[v2_index,'time'] = 2\n",
    "v2_index_te = (cox_te['y2'] == 1) & (cox_te['y1'] == 0)\n",
    "cox_te.loc[v2_index_te,'event'] = 1\n",
    "cox_te.loc[v2_index_te,'time'] = 2\n",
    "\n",
    "## incidence in V1\n",
    "v3_index = (cox_tr['y3'] == 1) & (cox_tr['y1'] == 0) & (cox_tr['y2'] == 0)\n",
    "cox_tr.loc[v3_index,'event'] = 1\n",
    "v3_index_te = (cox_te['y3'] == 1) & (cox_te['y1'] == 0) & (cox_te['y2'] == 0)\n",
    "cox_te.loc[v3_index_te,'event'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3237e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative true outcome: Y1, Y2, Y3\n",
    "cox_te['Y1'] = cox_te['y1']\n",
    "\n",
    "cox_te['Y2'] = cox_te['Y1']\n",
    "cox_te.loc[cox_te['y2'] == 1, 'Y2'] = 1\n",
    "\n",
    "cox_te['Y3'] = cox_te['Y2']\n",
    "cox_te.loc[cox_te['y3'] == 1, 'Y3'] = 1\n",
    "\n",
    "cox_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### M1 without nses #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c086d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "\n",
    "df_m1 = cox_tr.loc[:, ~cox_tr.columns.isin(['nSES', 'nbSESpc2score', 'y1', 'y2', 'y3'])]\n",
    "\n",
    "m1 = CoxPHFitter()\n",
    "m1.fit(df_m1, duration_col='time', event_col='event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3010d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "\n",
    "m1.print_summary()\n",
    "\n",
    "m1.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cfa7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1\n",
    "plt.hist(m1_sf.loc[:, 1], color = '#1f77b4', edgecolor = 'black',\n",
    "         bins = 50)\n",
    "plt.title('M1 - predicted hazards for V1')\n",
    "plt.xlabel('hazards')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbcb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102582c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_sf = np.transpose(m1.predict_survival_function(cox_te))\n",
    "m1_v3 = CoxMetrics(cox_te, m1_sf, visit = 3)\n",
    "m1_merge = m1_v3.data[['gender', 'nSES', 'Y3', 'sf_V3', 'pred_V3']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e66d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### M2 with binary nSES #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "\n",
    "df_m2 = cox_tr.loc[:, ~cox_tr.columns.isin(['nbSESpc2score', 'y1', 'y2', 'y3'])]\n",
    "\n",
    "m2 = CoxPHFitter()\n",
    "m2.fit(df_m2, duration_col='time', event_col='event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "m2.print_summary()\n",
    "m2.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_sf = np.transpose(m2.predict_survival_function(cox_te))\n",
    "m2_v3 = CoxMetrics(cox_te, m2_sf, visit = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3248630",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_merge = m2_v3.data[['sf_V3', 'pred_V3']]\n",
    "m2_merge = m2_merge.rename(columns={\"sf_V3\": \"m2_sf_V3\",\n",
    "                                   'pred_V3': 'm2_pred_V3'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### M3 with continuous nSES score #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6419afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "\n",
    "df_m3 = cox_tr.loc[:, ~cox_tr.columns.isin(['nSES', 'y1', 'y2', 'y3'])]\n",
    "\n",
    "m3 = CoxPHFitter()\n",
    "m3.fit(df_m3, duration_col='time', event_col='event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "m3.print_summary()\n",
    "m3.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1037e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_sf = np.transpose(m3.predict_survival_function(cox_te))\n",
    "m3_v3 = CoxMetrics(cox_te, m3_sf, visit = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91054167",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_merge = m3_v3.data[['sf_V3', 'pred_V3']]\n",
    "m3_merge = m3_merge.rename(columns={\"sf_V3\": \"m3_sf_V3\",\n",
    "                                   'pred_V3': 'm3_pred_V3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine predictions from 3 models\n",
    "test_df = pd.concat([m1_merge, m2_merge, m3_merge], axis = 1)\n",
    "test_df.to_csv('data/cox_predictions.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d478ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df['sf_V3'].mean())\n",
    "print(test_df['m2_sf_V3'].mean())\n",
    "print(test_df['m3_sf_V3'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### prediction comparisons ##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874318dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# focus on subjects that have dif labels in 3 models\n",
    "consistent_subj_index = (test_df['pred_V3'] == test_df['m2_pred_V3'] ) & ( test_df['m2_pred_V3'] == test_df['m3_pred_V3'])\n",
    "inconsistent_subj = test_df.loc[~consistent_subj_index, :]\n",
    "\n",
    "f_low = inconsistent_subj.loc[(inconsistent_subj['nSES'] == 0)&(inconsistent_subj['gender'] == 0),:]\n",
    "f_high = inconsistent_subj.loc[(inconsistent_subj['nSES'] == 1)&(inconsistent_subj['gender'] == 0),:]\n",
    "\n",
    "m_low = inconsistent_subj.loc[(inconsistent_subj['nSES'] == 0)&(inconsistent_subj['gender'] == 1),:]\n",
    "m_high = inconsistent_subj.loc[(inconsistent_subj['nSES'] == 1)&(inconsistent_subj['gender'] == 1),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa11974",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((inconsistent_subj['m3_pred_V3'] - inconsistent_subj['pred_V3']) == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad19818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### cali plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration plot prep\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms     \n",
    "from matplotlib import lines\n",
    "\n",
    "# function to add line using slope and intercept\n",
    "def abline(slope, intercept):\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '-', color='black')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot 1: all test data, bin by \n",
    "nses0_y, nses0_x = calibration_curve(test_df['Y3'], test_df['sf_V3'], n_bins=10,strategy = 'quantile')\n",
    "nses1_y, nses1_x = calibration_curve(test_df['Y3'], test_df['m2_sf_V3'], n_bins=10, strategy = 'quantile')\n",
    "nsescon_y, nsescon_x = calibration_curve(test_df['Y3'], test_df['m3_sf_V3'], n_bins=10, strategy = 'quantile')\n",
    "\n",
    "# calibration curves\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(nses1_x,nses1_y, marker='o', linewidth=1, label='with binary nSES')\n",
    "plt.plot(nses0_x, nses0_y, marker='o', linewidth=1, label='without nSES')\n",
    "plt.plot(nsescon_x, nsescon_y, marker='o', linewidth=1, label='with continuous nSES')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "abline(1, 0)\n",
    "fig.suptitle('Calibration plot for Cox Model')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7211e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse from the idealized cali line\n",
    "mse_no_nses = sum((nses0_y - nses0_x)**2) / 10\n",
    "print(mse_no_nses)\n",
    "mse_bin_nses = sum((nses1_y - nses1_x)**2) / 10\n",
    "print(mse_bin_nses)\n",
    "mse_con_nses = sum((nsescon_y - nsescon_x)**2) / 10\n",
    "print(mse_con_nses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b61c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### customized bin cali plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomizedBin:\n",
    "    def __init__(self, threshold, true_data, pred_prob, model):  \n",
    "        self.threshold = threshold\n",
    "        self.true_data = true_data\n",
    "        self.pred_prob = pred_prob\n",
    "        self.model = model\n",
    "        \n",
    "        pred_0 = self.pred_prob[self.pred_prob < self.threshold]\n",
    "        self.n_0 = len(pred_0)\n",
    "        \n",
    "        pred_1 = self.pred_prob[self.pred_prob >= self.threshold]\n",
    "        self.n_1 = len(pred_1)\n",
    "        \n",
    "        self.prob_pred = [np.mean(pred_0), np.mean(pred_1)]\n",
    "        \n",
    "        prob_true_0 = sum(self.true_data[self.pred_prob < self.threshold].values == 1) / self.n_0\n",
    "        prob_true_1= sum(self.true_data[self.pred_prob >= self.threshold].values == 1) / self.n_1\n",
    "        self.prob_true = [float(prob_true_0), float(prob_true_1)]\n",
    "        \n",
    "        weight = [(self.n_0)/(self.n_0+self.n_1),(self.n_1)/(self.n_0+self.n_1)]\n",
    "        weighted_mse = sum((np.array(self.prob_true) - np.array(self.prob_pred)) * weight)/2\n",
    "        \n",
    "        print('Weighted MSE of model',self.model,'=',weighted_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1223111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole test set\n",
    "\n",
    "# threshold: \n",
    "# without nses = 0.115\n",
    "# with binary nses = 0.109\n",
    "# with nses score = 0.087\n",
    "\n",
    "\n",
    "# bin the test set on threshold\n",
    "no_nses = CustomizedBin(threshold = 0.115, true_data = test_df['Y3'], pred_prob = test_df['sf_V3'], model = 'without nSES')\n",
    "bin_nses = CustomizedBin(threshold = 0.109, true_data = test_df['Y3'], pred_prob = test_df['m2_sf_V3'],model = 'with binary nSES')\n",
    "con_nses = CustomizedBin(threshold = 0.087, true_data = test_df['Y3'], pred_prob = test_df['m3_sf_V3'], model = 'with continuous nSES score')\n",
    "\n",
    "\n",
    "# calibration curves\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(no_nses.prob_pred, no_nses.prob_true, marker='o', linewidth=1, label='without nSES')\n",
    "ax.plot([0.115,0.115],[0.05,0.15], color = '#1f77b4', linestyle='dashed')\n",
    "plt.plot(bin_nses.prob_pred,bin_nses.prob_true, marker='o', linewidth=1, label='with binary nSES')\n",
    "ax.plot([0.109,0.109],[0.05,0.15], color = 'orange', linestyle='dashed')\n",
    "plt.plot(con_nses.prob_pred, con_nses.prob_true, marker='o', linewidth=1, label='with continuous nSES')\n",
    "ax.plot([0.087,0.087],[0.05,0.15], color = 'green', linestyle='dashed')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "abline(1, 0)\n",
    "fig.suptitle('Calibration plot for Cox Model')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03992246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgroups\n",
    "\n",
    "low_nses = test_df.loc[test_df['nSES'] == 0,:]\n",
    "high_nses = test_df.loc[test_df['nSES'] == 1,:]\n",
    "\n",
    "f_low = test_df.loc[(test_df['nSES'] == 0)&(test_df['gender'] == 0),:]\n",
    "f_high = test_df.loc[(test_df['nSES'] == 1)&(test_df['gender'] == 0),:]\n",
    "\n",
    "m_low = test_df.loc[(test_df['nSES'] == 0)&(test_df['gender'] == 1),:]\n",
    "m_high = test_df.loc[(test_df['nSES'] == 1)&(test_df['gender'] == 1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_nses\n",
    "\n",
    "# bin the test set on threshold\n",
    "no_nses = CustomizedBin(threshold = 0.115, true_data = high_nses['Y3'], pred_prob = high_nses['sf_V3'], model = 'without nSES')\n",
    "bin_nses = CustomizedBin(threshold = 0.109, true_data = high_nses['Y3'], pred_prob = high_nses['m2_sf_V3'],model = 'with binary nSES')\n",
    "con_nses = CustomizedBin(threshold = 0.087, true_data = high_nses['Y3'], pred_prob = high_nses['m3_sf_V3'], model = 'with continuous nSES score')\n",
    "\n",
    "# calibration curves\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(no_nses.prob_pred, no_nses.prob_true, marker='o', linewidth=1, label='without nSES')\n",
    "ax.plot([0.115,0.115],[0.05,0.20], color = '#1f77b4', linestyle='dashed')\n",
    "plt.plot(bin_nses.prob_pred,bin_nses.prob_true, marker='o', linewidth=1, label='with binary nSES')\n",
    "ax.plot([0.109,0.109],[0.05,0.20], color = 'orange', linestyle='dashed')\n",
    "plt.plot(con_nses.prob_pred, con_nses.prob_true, marker='o', linewidth=1, label='with continuous nSES')\n",
    "ax.plot([0.087,0.087],[0.05,0.20], color = 'green', linestyle='dashed')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "abline(1, 0)\n",
    "fig.suptitle('Calibration plot for Cox Model high nSES group')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### cali plot with self-defined bins (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cfc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomizedBin3:\n",
    "    def __init__(self, threshold, true_data, pred_prob, model):   ## threshold is now a list with two values\n",
    "        self.threshold = threshold\n",
    "        self.true_data = true_data\n",
    "        self.pred_prob = pred_prob\n",
    "        self.model = model\n",
    "        \n",
    "        pred_low = self.pred_prob[self.pred_prob < self.threshold[0]]\n",
    "        self.n_low = len(pred_low)\n",
    "        \n",
    "        med_index = (self.pred_prob >= self.threshold[0]) & (self.pred_prob <= self.threshold[1])\n",
    "        pred_med = self.pred_prob[med_index]\n",
    "        self.n_med = len(pred_med)\n",
    "        \n",
    "        pred_high = self.pred_prob[self.pred_prob >= self.threshold[1]]\n",
    "        self.n_high = len(pred_high)\n",
    "        \n",
    "        self.prob_pred = [np.mean(pred_low), np.mean(pred_med), np.mean(pred_high)]\n",
    "        \n",
    "        prob_true_low = sum(self.true_data[self.pred_prob < self.threshold[0]].values == 1) / self.n_low\n",
    "        prob_true_med = sum(self.true_data[med_index].values == 1) / self.n_med\n",
    "        prob_true_high = sum(self.true_data[self.pred_prob >= self.threshold[1]].values == 1) / self.n_high\n",
    "        self.prob_true = [float(prob_true_low), float(prob_true_med), float(prob_true_high)]\n",
    "        \n",
    "        tot_n = self.n_low + self.n_med + self.n_high\n",
    "        weight = [self.n_low/tot_n , self.n_med/tot_n, self.n_high/tot_n]\n",
    "        weighted_mse = sum((np.array(self.prob_true) - np.array(self.prob_pred)) * weight)/3\n",
    "        \n",
    "        print('Weighted MSE of model',self.model,'=',weighted_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole test set\n",
    "\n",
    "threshold = [0.1, 0.2]\n",
    "\n",
    "# bin the test set on threshold\n",
    "no_nses = CustomizedBin3(threshold = threshold, true_data = test_df['Y3'], pred_prob = test_df['sf_V3'], model = 'without nSES')\n",
    "bin_nses = CustomizedBin3(threshold = threshold, true_data = test_df['Y3'], pred_prob = test_df['m2_sf_V3'],model = 'with binary nSES')\n",
    "con_nses = CustomizedBin3(threshold = threshold, true_data = test_df['Y3'], pred_prob = test_df['m3_sf_V3'], model = 'with continuous nSES score')\n",
    "\n",
    "\n",
    "# calibration curves\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(no_nses.prob_pred, no_nses.prob_true, marker='o', linewidth=1, label='without nSES')\n",
    "plt.plot(bin_nses.prob_pred,bin_nses.prob_true, marker='o', linewidth=1, label='with binary nSES')\n",
    "plt.plot(con_nses.prob_pred, con_nses.prob_true, marker='o', linewidth=1, label='with continuous nSES')\n",
    "ax.plot([0.1,0.1],[0.05,0.15], color = 'black', linestyle='dashed')\n",
    "ax.plot([0.2,0.2],[0.15,0.25], color = 'black', linestyle='dashed')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "abline(1, 0)\n",
    "fig.suptitle('Calibration plot for Cox Model')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c40786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgroups\n",
    "\n",
    "threshold = [0.1, 0.2]\n",
    "\n",
    "# bin the test set on threshold\n",
    "no_nses = CustomizedBin3(threshold = threshold, true_data = high_nses['Y3'], pred_prob = high_nses['sf_V3'], model = 'without nSES')\n",
    "bin_nses = CustomizedBin3(threshold = threshold, true_data = high_nses['Y3'], pred_prob = high_nses['m2_sf_V3'],model = 'with binary nSES')\n",
    "con_nses = CustomizedBin3(threshold = threshold, true_data = high_nses['Y3'], pred_prob = high_nses['m3_sf_V3'], model = 'with continuous nSES score')\n",
    "\n",
    "\n",
    "# calibration curves\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(no_nses.prob_pred, no_nses.prob_true, marker='o', linewidth=1, label='without nSES')\n",
    "plt.plot(bin_nses.prob_pred,bin_nses.prob_true, marker='o', linewidth=1, label='with binary nSES')\n",
    "plt.plot(con_nses.prob_pred, con_nses.prob_true, marker='o', linewidth=1, label='with continuous nSES')\n",
    "ax.plot([0.1,0.1],[0.05,0.15], color = 'black', linestyle='dashed')\n",
    "ax.plot([0.2,0.2],[0.15,0.25], color = 'black', linestyle='dashed')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "abline(1, 0)\n",
    "fig.suptitle('Calibration plot for Cox Model - high_nses')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
