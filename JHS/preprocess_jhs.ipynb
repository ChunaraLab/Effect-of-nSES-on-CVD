{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1978543",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3401a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d5707",
   "metadata": {},
   "source": [
    "## Nb food and physical facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635f06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ = \"../Data/JHS/jhs_nets.csv\"\n",
    "nets_data = pd.read_csv(filename_)\n",
    "\n",
    "nets_data = nets_data[nets_data['exam'] == 'exam1']\n",
    "nets_data = nets_data[['SUBJID', 'S1FAV', 'S1PAI']]\n",
    "nets_data = nets_data.rename(columns={\"SUBJID\": \"subjid\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfb033",
   "metadata": {},
   "source": [
    "## racial segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "446d8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ = \"../Data/JHS/jhs_rs.csv\"\n",
    "rs_data = pd.read_csv(filename_)\n",
    "\n",
    "rs_data = rs_data[rs_data['exam'] == 'exam1']\n",
    "rs_data = rs_data[['SUBJID','G_bla_rk']]\n",
    "\n",
    "rs_data = rs_data.rename(columns={\"SUBJID\": \"subjid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa198af9",
   "metadata": {},
   "source": [
    "## other covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18f2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ = \"../Data/JHS/analysis.csv\"\n",
    "analysis_data = pd.read_csv(filename_)\n",
    "\n",
    "# select visit 1\n",
    "analysis_data = analysis_data[analysis_data['visit']==1]\n",
    "\n",
    "analysis_data = analysis_data[['subjid', \n",
    "                               'nbSESpc2score',\n",
    "                               'nutrition3cat','PA3cat','fmlyinc','alc','currentSmoker',\n",
    "                              'age','sex','Diabetes','hdl','totchol','sbp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e37d1",
   "metadata": {},
   "source": [
    "## event dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15a0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = pd.read_csv(\"../data_processed/JHS/jhs_event.csv\")\n",
    "\n",
    "event_data = event_data[['subjid', 'cvd_10y_HF','cvd_10y_noHF']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0de55",
   "metadata": {},
   "source": [
    "## merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27197211",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = event_data.merge(nets_data, how='left', on=['subjid'])\n",
    "merge2 = merge1.merge(rs_data, how='left', on=['subjid'])\n",
    "merge3 = merge2.merge(analysis_data, how='left', on=['subjid'])\n",
    "merge = merge3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23821091",
   "metadata": {},
   "outputs": [],
   "source": [
    "## map gender and income\n",
    "\n",
    "gender_mapping = {'Female':0,'Male':1}\n",
    "income_mapping = {'A':1,'B':1,'C':1,\n",
    "                 'D':2,'E':2,'F':2,\n",
    "                 'G':3,'H':3,'I':3,\n",
    "                 'J':4,'K':4}\n",
    "merge = merge.assign(gender = merge['sex'].map(gender_mapping))\n",
    "merge = merge.assign(fmlyinc = merge['fmlyinc'].map(income_mapping))\n",
    "\n",
    "merge_raw = merge.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53a0d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename \n",
    "\n",
    "merge_raw = merge_raw.rename(columns = {'nbSESpc2score': 'nSES',\n",
    "                            'S1FAV': 'nFavFood',\n",
    "                            'S1PAI': 'nPhysFac', \n",
    "                            'G_bla_rk': 'nRS', \n",
    "                            'nutrition3cat': 'nutrition', \n",
    "                            'PA3cat': 'PhysAct',\n",
    "                            'fmlyinc': 'FamIncome'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22406184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_raw.to_csv('../data_processed/JHS/jhs_raw.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f3ea0",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1653035d",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d8c8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_cat(df,cat_feat):\n",
    "    for feat in cat_feat:\n",
    "        df[feat].fillna(df[feat].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def fillna_cont(df,cont_feat):\n",
    "    df= df.fillna((df[cont_feat].mean()))\n",
    "    return df\n",
    "\n",
    "\n",
    "def quantile_exp(df,con_exp_feat):\n",
    "    for feat in con_exp_feat:\n",
    "        df[feat] = df[feat].transform(lambda x: pd.qcut(x.rank(method='first'), \n",
    "                                                         q = [0, 0.25, 0.5, 0.75, 1], labels = [1,2,3,4]))\n",
    "        df[feat] = pd.to_numeric(df[feat])\n",
    "    return df\n",
    "\n",
    "def standardize(df,con_index):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df[con_index],) \n",
    "    df[con_index] = scaler.transform(df[con_index], copy = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "## complete pipeline\n",
    "\n",
    "def process(df,cont_feat,cat_feat,con_exp_feat):\n",
    "    \n",
    "    df = fillna_cat(df,cat_feat)\n",
    "    \n",
    "    df = fillna_cont(df,cont_feat)\n",
    "    df = standardize(df,cont_feat)\n",
    "        \n",
    "    df = fillna_cont(df,con_exp_feat)\n",
    "    df = quantile_exp(df,con_exp_feat)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ae22a",
   "metadata": {},
   "source": [
    "## process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4231e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_exp_feat = ['nSES','nFavFood','nPhysFac','nRS']\n",
    "\n",
    "cont_feat = ['sbp', 'hdl', 'totchol']\n",
    "\n",
    "cat_feat = ['age','nutrition','PhysAct','currentSmoker','Diabetes', 'gender', 'FamIncome','alc']\n",
    "\n",
    "jhs_preprocessed = merge_raw.copy()\n",
    "jhs_imputed = merge_raw.copy()\n",
    "jhs_cate = merge_raw.copy()\n",
    "jhs_std = merge_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessed\n",
    "\n",
    "jhs_preprocessed = process(jhs_preprocessed,cont_feat,cat_feat,con_exp_feat)\n",
    "\n",
    "#jhs_preprocessed.to_csv('../data_processed/JHS/jhs_pre.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4be055",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### standardization only #####\n",
    "##### final analysis data #####\n",
    "\n",
    "jhs_std = jhs_std.dropna()\n",
    "\n",
    "cols_to_standardize = ['nSES','nFavFood','nPhysFac','nRS', 'sbp', 'hdl', 'totchol']\n",
    "scaler = StandardScaler()\n",
    "jhs_std[cols_to_standardize] = scaler.fit_transform(jhs_std[cols_to_standardize])\n",
    "\n",
    "#jhs_std.to_csv('../data_processed/JHS/jhs_std.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### categorization only\n",
    "\n",
    "# standardize\n",
    "cols_to_standardize = ['nSES','nFavFood','nPhysFac','nRS', 'sbp', 'hdl', 'totchol']\n",
    "scaler = StandardScaler()\n",
    "jhs_cate[cols_to_standardize] = scaler.fit_transform(jhs_cate[cols_to_standardize])\n",
    "\n",
    "# categorize\n",
    "jhs_cate = quantile_exp(jhs_cate,con_exp_feat)\n",
    "\n",
    "#jhs_cate.to_csv('../data_processed/JHS/jhs_cate.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d823194",
   "metadata": {},
   "outputs": [],
   "source": [
    "### missing imputation only\n",
    "\n",
    "cat_feat = ['FamIncome', 'nutrition', 'PhysAct',\n",
    "           'currentSmoker','alc','Diabetes']\n",
    "cont_feat = ['nSES','nFavFood','nPhysFac', 'nRS',\n",
    "           'hdl','totchol','sbp']\n",
    "\n",
    "jhs_imputed = fillna_cat(jhs_imputed,cat_feat)  \n",
    "jhs_imputed = fillna_cont(jhs_imputed,cont_feat)  \n",
    "\n",
    "#jhs_imputed.to_csv('../data_processed/JHS/jhs_imputed.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
